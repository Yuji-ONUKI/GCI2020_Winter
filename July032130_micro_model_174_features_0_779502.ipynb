{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "July032130_micro-model-174-features-0.779502",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuji-ONUKI/GCI2020_Winter/blob/main/July032130_micro_model_174_features_0_779502.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a Micro Model Study on Home Credit\n",
        "\n",
        "The Home Credit Default Risk dataset on the Kaggle is subjected as a final project of my DS/ML bootcamp, and I have spent a period of three weeks on this project. I developed various models and quite a large number of them having AUC scores better than 0.8 ( highest one +0.804). Unfortunately, I could not run any full version of my models on Kaggle because of insufficient RAM issue even though datasets are zipped to almost 4 times by integer/float dtype conversion on my datasets. In addition, I made a bleend boosting study to acheive highest AUC score (0.81128, much highers possible) on Kaggle (https://www.kaggle.com/hikmetsezen/blend-boosting-for-home-credit-default-risk).\n",
        "\n",
        "Here I would like to share my micro model study with you. This micro model has only 174 features and is able to reach better than 0.8 AUC score. Micro model is developed on my base model via successive feature elimination and addition procedure, which is developed by myself. My ambition is that tremendously increasing number of feature is not always necessary to improve performance of model! \n",
        "\n",
        "Mostly I use Colab Pro to compute LigthGBM calculations with 5-fold CV on GPUs. My models have 900-1800 features. \n",
        "\n",
        "I have a limited knowledge about the credit finance, therefore, I combined many Kaggle notebooks for expending number of features as much as I desire and/or acceptance of my LigthGBM models harvesting further enhance scores. I would like to thank these contributors. Some of them are listed here:\n",
        "* https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features <=-- my models are based on this study\n",
        "* https://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution\n",
        "* https://www.kaggle.com/sangseoseo/oof-all-home-credit-default-risk <=-- in most cases these hyperparameters are used\n",
        "* https://www.kaggle.com/ashishpatel26/different-basic-blends-possible <=-- thank for blending idea\n",
        "* https://www.kaggle.com/mathchi/home-credit-risk-with-detailed-feature-engineering\n",
        "* https://www.kaggle.com/windofdl/kernelf68f763785\n",
        "* https://www.kaggle.com/meraxes10/lgbm-credit-default-prediction\n",
        "* https://www.kaggle.com/luudactam/hc-v500\n",
        "* https://www.kaggle.com/aantonova/aggregating-all-tables-in-one-dataset\n",
        "* https://www.kaggle.com/wanakon/kernel24647bb75c"
      ],
      "metadata": {
        "id": "lw9PwzlO0Rpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install lightgbm==2.3.1\n",
        "# import lightgbm\n",
        "# lightgbm.__version__"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "5RKGN2JA0Rpz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "import gc\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "trusted": true,
        "id": "CnuASwW10Rp1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run functions and pre_settings\n",
        "def one_hot_encoder(df, nan_as_category=True):\n",
        "    original_columns = list(df.columns)\n",
        "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
        "    new_columns = [c for c in df.columns if c not in original_columns]\n",
        "    return df, new_columns\n",
        "\n",
        "def group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
        "    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n",
        "    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n",
        "                               for e in agg_df.columns.tolist()])\n",
        "    return agg_df.reset_index()\n",
        "\n",
        "def group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
        "    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n",
        "    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n",
        "\n",
        "def do_sum(dataframe, group_cols, counted, agg_name):\n",
        "    gp = dataframe[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(columns={counted: agg_name})\n",
        "    dataframe = dataframe.merge(gp, on=group_cols, how='left')\n",
        "    return dataframe\n",
        "\n",
        "def reduce_mem_usage(dataframe):\n",
        "    m_start = dataframe.memory_usage().sum() / 1024 ** 2\n",
        "    for col in dataframe.columns:\n",
        "        col_type = dataframe[col].dtype\n",
        "        if col_type != object:\n",
        "            c_min = dataframe[col].min()\n",
        "            c_max = dataframe[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    dataframe[col] = dataframe[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    dataframe[col] = dataframe[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    dataframe[col] = dataframe[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    dataframe[col] = dataframe[col].astype(np.int64)\n",
        "            elif str(col_type)[:5] == 'float':\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    dataframe[col] = dataframe[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    dataframe[col] = dataframe[col].astype(np.float32)\n",
        "                else:\n",
        "                    dataframe[col] = dataframe[col].astype(np.float64)\n",
        "\n",
        "    m_end = dataframe.memory_usage().sum() / 1024 ** 2\n",
        "    return dataframe\n",
        "\n",
        "nan_as_category = True"
      ],
      "metadata": {
        "trusted": true,
        "id": "F25iusIZ0Rp3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def application():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/GCI/02.（公開）コンペ2-20220621T094535Z-001.zip (Unzipped Files)/02.（公開）コンペ2/input/train.csv\")\n",
        "    test_df = pd.read_csv(\"/content/drive/MyDrive/GCI/02.（公開）コンペ2-20220621T094535Z-001.zip (Unzipped Files)/02.（公開）コンペ2/input/test.csv\")\n",
        "    # general cleaning procedures\n",
        "    df = df[df['CODE_GENDER'] != 'XNA']\n",
        "    df = df[df['AMT_INCOME_TOTAL'] < 20000000] # remove a outlier 117M\n",
        "    # test_records shouldn't be omitted\n",
        "    df = df.append(test_df).reset_index()\n",
        "\n",
        "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
        "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True) # set null value\n",
        "    df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True) # set null value\n",
        "    #\n",
        "    df['REGION_4']=0\n",
        "    df.loc[df['REGION_POPULATION_RELATIVE']==0.4622,'REGION_4']=1\n",
        "    df.loc[df['REGION_POPULATION_RELATIVE']==0.4622,'REGION_POPULATION_RELATIVE']=np.nan\n",
        "\n",
        "    df['REGION_7']=0\n",
        "    df.loc[df['REGION_POPULATION_RELATIVE']==0.072508,'REGION_7']=1\n",
        "    df.loc[df['REGION_POPULATION_RELATIVE']==0.072508,'REGION_POPULATION_RELATIVE']=np.nan\n",
        "\n",
        "    df['OWN_CAR_AGE_64']=0\n",
        "    df.loc[df['OWN_CAR_AGE']==64,'OWN_CAR_AGE_64']=1\n",
        "    df.loc[df['OWN_CAR_AGE']==64,'OWN_CAR_AGE']=np.nan\n",
        "\n",
        "    df['OWN_CAR_AGE_65']=0\n",
        "    df.loc[df['OWN_CAR_AGE']==65,'OWN_CAR_AGE_65']=1\n",
        "    df.loc[df['OWN_CAR_AGE']==65,'OWN_CAR_AGE']=np.nan\n",
        "\n",
        "    # Categorical features with Binary encode (0 or 1; two categories)\n",
        "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
        "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
        "    \n",
        "    # Categorical features with One-Hot encode\n",
        "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
        "\n",
        "    # Flag_document features - count and kurtosis\n",
        "    docs = [f for f in df.columns if 'FLAG_DOC' in f]\n",
        "    df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n",
        "    df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)\n",
        "\n",
        "    def get_age_label(days_birth):\n",
        "        \"\"\" Return the age group label (int). \"\"\"\n",
        "        age_years = -days_birth / 365\n",
        "        if age_years < 27: return 1\n",
        "        elif age_years < 40: return 2\n",
        "        elif age_years < 50: return 3\n",
        "        elif age_years < 65: return 4\n",
        "        elif age_years < 99: return 5\n",
        "        else: return 0\n",
        "    # Categorical age - based on target=1 plot\n",
        "    df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))\n",
        "\n",
        "    # New features based on External sources\n",
        "    df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
        "    df['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3\n",
        "    np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
        "    for function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n",
        "        feature_name = 'EXT_SOURCES_{}'.format(function_name.upper())\n",
        "        df[feature_name] = eval('np.{}'.format(function_name))(\n",
        "            df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1)\n",
        "\n",
        "    # Some simple new features (percentages)\n",
        "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
        "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
        "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
        "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
        "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
        "\n",
        "    # Credit ratios\n",
        "    df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
        "    \n",
        "    # Income ratios\n",
        "    df['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
        "    df['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']\n",
        "    \n",
        "    # Time ratios\n",
        "    df['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\n",
        "    df['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
        "    df['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
        "    df['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
        "\n",
        "    # EXT_SOURCE_X FEATURE\n",
        "    df['APPS_EXT_SOURCE_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
        "    df['APPS_EXT_SOURCE_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
        "    df['APPS_EXT_SOURCE_STD'] = df['APPS_EXT_SOURCE_STD'].fillna(df['APPS_EXT_SOURCE_STD'].mean())\n",
        "    df['APP_SCORE1_TO_BIRTH_RATIO'] = df['EXT_SOURCE_1'] / (df['DAYS_BIRTH'] / 365.25)\n",
        "    df['APP_SCORE2_TO_BIRTH_RATIO'] = df['EXT_SOURCE_2'] / (df['DAYS_BIRTH'] / 365.25)\n",
        "    df['APP_SCORE3_TO_BIRTH_RATIO'] = df['EXT_SOURCE_3'] / (df['DAYS_BIRTH'] / 365.25)\n",
        "    df['APP_SCORE1_TO_EMPLOY_RATIO'] = df['EXT_SOURCE_1'] / (df['DAYS_EMPLOYED'] / 365.25)\n",
        "    df['APP_EXT_SOURCE_2*EXT_SOURCE_3*DAYS_BIRTH'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['DAYS_BIRTH']\n",
        "    df['APP_SCORE1_TO_FAM_CNT_RATIO'] = df['EXT_SOURCE_1'] / df['CNT_FAM_MEMBERS']\n",
        "    df['APP_SCORE1_TO_GOODS_RATIO'] = df['EXT_SOURCE_1'] / df['AMT_GOODS_PRICE']\n",
        "    df['APP_SCORE1_TO_CREDIT_RATIO'] = df['EXT_SOURCE_1'] / df['AMT_CREDIT']\n",
        "    df['APP_SCORE1_TO_SCORE2_RATIO'] = df['EXT_SOURCE_1'] / df['EXT_SOURCE_2']\n",
        "    df['APP_SCORE1_TO_SCORE3_RATIO'] = df['EXT_SOURCE_1'] / df['EXT_SOURCE_3']\n",
        "    df['APP_SCORE2_TO_CREDIT_RATIO'] = df['EXT_SOURCE_2'] / df['AMT_CREDIT']\n",
        "    df['APP_SCORE2_TO_REGION_RATING_RATIO'] = df['EXT_SOURCE_2'] / df['REGION_RATING_CLIENT']\n",
        "    df['APP_SCORE2_TO_CITY_RATING_RATIO'] = df['EXT_SOURCE_2'] / df['REGION_RATING_CLIENT_W_CITY']\n",
        "    df['APP_SCORE2_TO_POP_RATIO'] = df['EXT_SOURCE_2'] / df['REGION_POPULATION_RELATIVE']\n",
        "    df['APP_SCORE2_TO_PHONE_CHANGE_RATIO'] = df['EXT_SOURCE_2'] / df['DAYS_LAST_PHONE_CHANGE']\n",
        "    df['APP_EXT_SOURCE_1*EXT_SOURCE_2'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2']\n",
        "    df['APP_EXT_SOURCE_1*EXT_SOURCE_3'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_3']\n",
        "    df['APP_EXT_SOURCE_2*EXT_SOURCE_3'] = df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
        "    df['APP_EXT_SOURCE_1*DAYS_EMPLOYED'] = df['EXT_SOURCE_1'] * df['DAYS_EMPLOYED']\n",
        "    df['APP_EXT_SOURCE_2*DAYS_EMPLOYED'] = df['EXT_SOURCE_2'] * df['DAYS_EMPLOYED']\n",
        "    df['APP_EXT_SOURCE_3*DAYS_EMPLOYED'] = df['EXT_SOURCE_3'] * df['DAYS_EMPLOYED']\n",
        "\n",
        "    # AMT_INCOME_TOTAL : income\n",
        "    # CNT_FAM_MEMBERS  : the number of family members\n",
        "    df['APPS_GOODS_INCOME_RATIO'] = df['AMT_GOODS_PRICE'] / df['AMT_INCOME_TOTAL']\n",
        "    df['APPS_CNT_FAM_INCOME_RATIO'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
        "    \n",
        "    # DAYS_BIRTH : Client's age in days at the time of application\n",
        "    # DAYS_EMPLOYED : How many days before the application the person started current employment\n",
        "    df['APPS_INCOME_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
        "\n",
        "    # other feature from better than 0.8\n",
        "    df['CREDIT_TO_GOODS_RATIO_2'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
        "    df['APP_AMT_INCOME_TOTAL_12_AMT_ANNUITY_ratio'] = df['AMT_INCOME_TOTAL'] / 12. - df['AMT_ANNUITY']\n",
        "    df['APP_INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
        "    df['APP_DAYS_LAST_PHONE_CHANGE_DAYS_EMPLOYED_ratio'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n",
        "    df['APP_DAYS_EMPLOYED_DAYS_BIRTH_diff'] = df['DAYS_EMPLOYED'] - df['DAYS_BIRTH']\n",
        "\n",
        "    print('\"Application_Train_Test\" final shape:', df.shape)\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "id": "0KlSb_-N0Rp5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = application()\n",
        "df = reduce_mem_usage(df)\n",
        "print('data types are converted for a reduced memory usage')\n",
        "df = df.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '_', x))\n",
        "print('names of feature are renamed')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMSeqXLu0RqG",
        "outputId": "d4933107-c808-4366-a43d-b1bdee562cd5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\"Application_Train_Test\" final shape: (232698, 219)\n",
            "data types are converted for a reduced memory usage\n",
            "names of feature are renamed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('===============================================', '\\n', '##### the ML in processing...')\n",
        "\n",
        "    # loading predicted result \n",
        "df_sub = df.loc[df['TARGET'].isnull(),['SK_ID_CURR', 'TARGET']]\n",
        "\n",
        "\n",
        "    # split train, and test datasets\n",
        "train_df = df[df['TARGET'].notnull()]\n",
        "test_df = df[df['TARGET'].isnull()]\n",
        "del df\n",
        "\n",
        "    # Expand train dataset with two times of test dataset including predicted results\n",
        "test_df.TARGET = np.where(df_sub.TARGET > 0.75, 1, 0)\n",
        "train_df = pd.concat([train_df, test_df], axis=0)\n",
        "train_df = pd.concat([train_df, test_df], axis=0)\n",
        "print(f'Train shape: {train_df.shape}, test shape: {test_df.shape} are loaded.')\n",
        "\n",
        "\n",
        "    # Cross validation model\n",
        "folds = KFold(n_splits=5, shuffle=True, random_state=2020)\n",
        "\n",
        "    # Create arrays and dataframes to store results\n",
        "oof_preds = np.zeros(train_df.shape[0])\n",
        "sub_preds = np.zeros(test_df.shape[0])\n",
        "\n",
        "\n",
        "    # limit number of feature to only 174!!!\n",
        "feats = ['index', 'ORGANIZATION_TYPE_Industry_type_5', 'NAME_EDUCATION_TYPE_Higher_education','REGION_RATING_CLIENT_W_CITY', 'NAME_HOUSING_TYPE_House_apartment', 'ANNUITY_INCOME_PERC', 'ORGANIZATION_TYPE_Services', 'ORGANIZATION_TYPE_Cleaning', 'ORGANIZATION_TYPE_Military',  'ORGANIZATION_TYPE_School',    'DAYS_BIRTH',  'OCCUPATION_TYPE_High_skill_tech_staff',  'OCCUPATION_TYPE_Private_service_staff',  'OCCUPATION_TYPE_HR_staff',  'CODE_GENDER','ORGANIZATION_TYPE_Advertising', 'EXT_SOURCE_3', 'OCCUPATION_TYPE_Managers', 'FLAG_OWN_REALTY',  'AMT_CREDIT', 'INCOME_PER_PERSON', 'ORGANIZATION_TYPE_Police', 'FLAG_WORK_PHONE', 'ORGANIZATION_TYPE_University', 'ORGANIZATION_TYPE_Medicine', 'ORGANIZATION_TYPE_Telecom', 'ORGANIZATION_TYPE_Housing', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL',  'REGION_POPULATION_RELATIVE', 'ORGANIZATION_TYPE_Electricity', 'REGION_RATING_CLIENT',  'DAYS_ID_PUBLISH', 'EXT_SOURCE_1', 'ORGANIZATION_TYPE_Realtor', 'OCCUPATION_TYPE_Laborers', 'ORGANIZATION_TYPE_Security', 'AMT_INCOME_TOTAL',  'PAYMENT_RATE', 'FLAG_OWN_CAR',  'ORGANIZATION_TYPE_Mobile', 'DAYS_EMPLOYED_PERC', 'INCOME_CREDIT_PERC',  'ORGANIZATION_TYPE_Postal', 'ORGANIZATION_TYPE_Insurance', 'OCCUPATION_TYPE_Accountants',  'ORGANIZATION_TYPE_Agriculture', 'EXT_SOURCE_2',  'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'ORGANIZATION_TYPE_Construction','REGION_4','REGION_7']#,'OWN_CAR_AGE_64','OWN_CAR_AGE_65']\n",
        "\n",
        "    # print final shape of dataset to evaluate by LightGBM\n",
        "print(f'only {len(feats)} features from a total {train_df.shape[1]} features are used for ML analysis')\n",
        "\n",
        "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
        "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
        "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
        "        clf = LGBMClassifier(nthread=-1,\n",
        "                            n_estimators=5000,\n",
        "                            learning_rate=0.01,\n",
        "                            max_depth=11,\n",
        "                            num_leaves=58,\n",
        "                            colsample_bytree=0.613,\n",
        "                            subsample=0.708,\n",
        "                            max_bin=407,\n",
        "                            reg_alpha=3.564,\n",
        "                            reg_lambda=4.930,\n",
        "                            min_child_weight=6,\n",
        "                            min_child_samples=165,\n",
        "                            silent=-1,\n",
        "                            verbose=-1,)\n",
        "\n",
        "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric='auc', verbose=500, early_stopping_rounds=500)\n",
        "\n",
        "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
        "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
        "\n",
        "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
        "        del clf, train_x, train_y, valid_x, valid_y\n",
        "\n",
        "print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
        "\n",
        "    # create submission file\n",
        "test_df['TARGET'] = sub_preds\n",
        "test_df['SK_ID_CURR']=test_df['SK_ID_CURR'].astype(int)\n",
        "test_df['TARGET']=round(test_df['TARGET']*100000)/100000\n",
        "test_df[['SK_ID_CURR', 'TARGET']].to_csv('submission.csv', index=False)\n",
        "print('a submission file is created')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShtFBB713YtD",
        "outputId": "0f06206d-f25d-4138-d398-de903f4757f1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================== \n",
            " ##### the ML in processing...\n",
            "Train shape: (294198, 219), test shape: (61500, 219) are loaded.\n",
            "only 53 features from a total 219 features are used for ML analysis\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's auc: 0.813303\ttraining's binary_logloss: 0.15718\tvalid_1's auc: 0.769099\tvalid_1's binary_logloss: 0.164648\n",
            "[1000]\ttraining's auc: 0.839968\ttraining's binary_logloss: 0.150505\tvalid_1's auc: 0.772151\tvalid_1's binary_logloss: 0.164085\n",
            "[1500]\ttraining's auc: 0.859869\ttraining's binary_logloss: 0.145448\tvalid_1's auc: 0.772254\tvalid_1's binary_logloss: 0.164138\n",
            "Early stopping, best iteration is:\n",
            "[1129]\ttraining's auc: 0.845441\ttraining's binary_logloss: 0.149122\tvalid_1's auc: 0.772405\tvalid_1's binary_logloss: 0.164051\n",
            "Fold  1 AUC : 0.772405\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's auc: 0.81114\ttraining's binary_logloss: 0.157359\tvalid_1's auc: 0.783036\tvalid_1's binary_logloss: 0.164271\n",
            "[1000]\ttraining's auc: 0.838642\ttraining's binary_logloss: 0.150767\tvalid_1's auc: 0.784602\tvalid_1's binary_logloss: 0.163516\n",
            "[1500]\ttraining's auc: 0.858846\ttraining's binary_logloss: 0.145759\tvalid_1's auc: 0.784691\tvalid_1's binary_logloss: 0.163474\n",
            "[2000]\ttraining's auc: 0.875301\ttraining's binary_logloss: 0.141376\tvalid_1's auc: 0.784668\tvalid_1's binary_logloss: 0.163473\n",
            "Early stopping, best iteration is:\n",
            "[1843]\ttraining's auc: 0.87024\ttraining's binary_logloss: 0.142729\tvalid_1's auc: 0.784811\tvalid_1's binary_logloss: 0.163453\n",
            "Fold  2 AUC : 0.784811\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's auc: 0.812957\ttraining's binary_logloss: 0.157313\tvalid_1's auc: 0.771692\tvalid_1's binary_logloss: 0.163908\n",
            "[1000]\ttraining's auc: 0.838975\ttraining's binary_logloss: 0.150876\tvalid_1's auc: 0.77582\tvalid_1's binary_logloss: 0.163017\n",
            "[1500]\ttraining's auc: 0.858353\ttraining's binary_logloss: 0.146007\tvalid_1's auc: 0.776682\tvalid_1's binary_logloss: 0.162859\n",
            "[2000]\ttraining's auc: 0.874795\ttraining's binary_logloss: 0.14166\tvalid_1's auc: 0.776755\tvalid_1's binary_logloss: 0.162864\n",
            "Early stopping, best iteration is:\n",
            "[1653]\ttraining's auc: 0.863344\ttraining's binary_logloss: 0.144678\tvalid_1's auc: 0.776878\tvalid_1's binary_logloss: 0.162821\n",
            "Fold  3 AUC : 0.776878\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's auc: 0.811957\ttraining's binary_logloss: 0.156318\tvalid_1's auc: 0.776009\tvalid_1's binary_logloss: 0.168353\n",
            "[1000]\ttraining's auc: 0.839562\ttraining's binary_logloss: 0.149723\tvalid_1's auc: 0.779689\tvalid_1's binary_logloss: 0.16745\n",
            "[1500]\ttraining's auc: 0.859668\ttraining's binary_logloss: 0.144796\tvalid_1's auc: 0.779865\tvalid_1's binary_logloss: 0.167425\n",
            "Early stopping, best iteration is:\n",
            "[1354]\ttraining's auc: 0.854246\ttraining's binary_logloss: 0.146156\tvalid_1's auc: 0.779967\tvalid_1's binary_logloss: 0.167393\n",
            "Fold  4 AUC : 0.779967\n",
            "Training until validation scores don't improve for 500 rounds.\n",
            "[500]\ttraining's auc: 0.811162\ttraining's binary_logloss: 0.158043\tvalid_1's auc: 0.777779\tvalid_1's binary_logloss: 0.161644\n",
            "[1000]\ttraining's auc: 0.838388\ttraining's binary_logloss: 0.151431\tvalid_1's auc: 0.781765\tvalid_1's binary_logloss: 0.160673\n",
            "[1500]\ttraining's auc: 0.857975\ttraining's binary_logloss: 0.146591\tvalid_1's auc: 0.782182\tvalid_1's binary_logloss: 0.16057\n",
            "[2000]\ttraining's auc: 0.87417\ttraining's binary_logloss: 0.142237\tvalid_1's auc: 0.781913\tvalid_1's binary_logloss: 0.160619\n",
            "Early stopping, best iteration is:\n",
            "[1599]\ttraining's auc: 0.861255\ttraining's binary_logloss: 0.145699\tvalid_1's auc: 0.782274\tvalid_1's binary_logloss: 0.160546\n",
            "Fold  5 AUC : 0.782274\n",
            "Full AUC score 0.779271\n",
            "a submission file is created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full AUC score 0.779271"
      ],
      "metadata": {
        "id": "sXqx3DHGenvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.loc[test_df['SK_ID_CURR']==187781]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "uYfHnviG-ztK",
        "outputId": "7b19ac38-ceeb-465a-a6a8-7dd5a7f11b4f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        index  SK_ID_CURR   TARGET  CODE_GENDER  FLAG_OWN_CAR  \\\n",
              "187777  16579      187781  0.08011            0             0   \n",
              "\n",
              "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
              "187777                1             1       117000000.0    562491.0   \n",
              "\n",
              "        AMT_ANNUITY  ...  APP_EXT_SOURCE_2_DAYS_EMPLOYED  \\\n",
              "187777      26194.5  ...                       -104.3125   \n",
              "\n",
              "        APP_EXT_SOURCE_3_DAYS_EMPLOYED  APPS_GOODS_INCOME_RATIO  \\\n",
              "187777                         -134.25                 0.003885   \n",
              "\n",
              "        APPS_CNT_FAM_INCOME_RATIO  APPS_INCOME_EMPLOYED_RATIO  \\\n",
              "187777                 39000000.0              -126898.047722   \n",
              "\n",
              "        CREDIT_TO_GOODS_RATIO_2  APP_AMT_INCOME_TOTAL_12_AMT_ANNUITY_ratio  \\\n",
              "187777                 1.237305                                  9723806.0   \n",
              "\n",
              "        APP_INCOME_TO_EMPLOYED_RATIO  \\\n",
              "187777                -126898.047722   \n",
              "\n",
              "        APP_DAYS_LAST_PHONE_CHANGE_DAYS_EMPLOYED_ratio  \\\n",
              "187777                                             NaN   \n",
              "\n",
              "        APP_DAYS_EMPLOYED_DAYS_BIRTH_diff  \n",
              "187777                            11696.0  \n",
              "\n",
              "[1 rows x 219 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6d86d33-0271-4559-8b24-409e707bb17e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>SK_ID_CURR</th>\n",
              "      <th>TARGET</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>AMT_CREDIT</th>\n",
              "      <th>AMT_ANNUITY</th>\n",
              "      <th>...</th>\n",
              "      <th>APP_EXT_SOURCE_2_DAYS_EMPLOYED</th>\n",
              "      <th>APP_EXT_SOURCE_3_DAYS_EMPLOYED</th>\n",
              "      <th>APPS_GOODS_INCOME_RATIO</th>\n",
              "      <th>APPS_CNT_FAM_INCOME_RATIO</th>\n",
              "      <th>APPS_INCOME_EMPLOYED_RATIO</th>\n",
              "      <th>CREDIT_TO_GOODS_RATIO_2</th>\n",
              "      <th>APP_AMT_INCOME_TOTAL_12_AMT_ANNUITY_ratio</th>\n",
              "      <th>APP_INCOME_TO_EMPLOYED_RATIO</th>\n",
              "      <th>APP_DAYS_LAST_PHONE_CHANGE_DAYS_EMPLOYED_ratio</th>\n",
              "      <th>APP_DAYS_EMPLOYED_DAYS_BIRTH_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187777</th>\n",
              "      <td>16579</td>\n",
              "      <td>187781</td>\n",
              "      <td>0.08011</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>117000000.0</td>\n",
              "      <td>562491.0</td>\n",
              "      <td>26194.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-104.3125</td>\n",
              "      <td>-134.25</td>\n",
              "      <td>0.003885</td>\n",
              "      <td>39000000.0</td>\n",
              "      <td>-126898.047722</td>\n",
              "      <td>1.237305</td>\n",
              "      <td>9723806.0</td>\n",
              "      <td>-126898.047722</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11696.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 219 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6d86d33-0271-4559-8b24-409e707bb17e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6d86d33-0271-4559-8b24-409e707bb17e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6d86d33-0271-4559-8b24-409e707bb17e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}